{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sandr\\Documents\\Personal-Files\\05-Projects\\gnn-optcg\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\torch_geometric\\typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "c:\\Users\\sandr\\Documents\\Personal-Files\\05-Projects\\gnn-optcg\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\torch_geometric\\typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "c:\\Users\\sandr\\Documents\\Personal-Files\\05-Projects\\gnn-optcg\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\torch_geometric\\typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(\n",
      "c:\\Users\\sandr\\Documents\\Personal-Files\\05-Projects\\gnn-optcg\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\torch_geometric\\typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
      "c:\\Users\\sandr\\Documents\\Personal-Files\\05-Projects\\gnn-optcg\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, GATConv, BatchNorm\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.utils import from_networkx, negative_sampling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "EFFECT_DIM = 384  # Dimension of the effect embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_card_attributes(file=\"data/labeled_cards.json\"):\n",
    "    \"\"\"\n",
    "    Load card attributes from JSON.\n",
    "    For each card, compute a text embedding for its \"effect\" using the sentence transformer.\n",
    "    \"\"\"\n",
    "    with open(file, \"r\") as f:\n",
    "        cards = json.load(f)\n",
    "    card_dict = {}\n",
    "    for card in cards:\n",
    "        effect_text = card.get(\"effect\", \"\").strip()\n",
    "        if effect_text:\n",
    "            effect_embedding = text_model.encode(effect_text)\n",
    "        else:\n",
    "            effect_embedding = np.zeros(EFFECT_DIM)\n",
    "        card[\"effect_embedding\"] = effect_embedding.tolist()\n",
    "        card_dict[card[\"id\"]] = card\n",
    "    return card_dict\n",
    "\n",
    "def load_card_synergies(file=\"data/card_synergies.graphml\"):\n",
    "    \"\"\"\n",
    "    Load known synergy relationships from a GraphML file.\n",
    "    \"\"\"\n",
    "    return nx.read_graphml(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(features):\n",
    "    scaler = MinMaxScaler()\n",
    "    return scaler.fit_transform(features)\n",
    "\n",
    "def convert_to_pyg(graphs, card_data):\n",
    "    \"\"\"\n",
    "    Converts a list of NetworkX graphs into PyTorch Geometric data objects.\n",
    "    Each node (card) feature vector includes:\n",
    "      - Basic numeric features (copies, cost, power, count(labels), counter)\n",
    "      - One-hot encoding for colors\n",
    "      - Hashed features for type and traits (as proxies)\n",
    "      - The effect text embedding (EFFECT_DIM dimensions)\n",
    "    We remove any unwanted edge attributes.\n",
    "    \"\"\"\n",
    "    pyg_graphs = []\n",
    "    base_feature_list = [\"copies\", \"cost\", \"power\", \"labels\", \"counter\", \"type\", \"traits\",\n",
    "                         \"color_Red\", \"color_Green\", \"color_Blue\", \"color_Purple\", \"color_Black\", \"color_Yellow\"]\n",
    "    effect_feature_list = [f\"effect_{i}\" for i in range(EFFECT_DIM)]\n",
    "    full_feature_list = base_feature_list + effect_feature_list\n",
    "\n",
    "    for G in graphs:\n",
    "        # Remove all edge attributes.\n",
    "        for u, v, d in G.edges(data=True):\n",
    "            d.clear()\n",
    "\n",
    "        node_features = []\n",
    "        for node in G.nodes():\n",
    "            card_id = node\n",
    "            card = card_data.get(card_id, {})\n",
    "            features = [\n",
    "                float(G.nodes[node].get(\"copies\", 1)),\n",
    "                float(card.get(\"cost\", 0)),\n",
    "                float(card.get(\"power\", 0)),\n",
    "                float(len(card.get(\"labels\", []))),\n",
    "                float(card.get(\"counter\", 0))\n",
    "            ]\n",
    "            colors = [\"Red\", \"Green\", \"Blue\", \"Purple\", \"Black\", \"Yellow\"]\n",
    "            features.extend([1.0 if c in card.get(\"color\", []) else 0.0 for c in colors])\n",
    "            # Use hash mod 10 for type and traits as a simple categorical proxy.\n",
    "            features.append(float(hash(card.get(\"type\", \"None\")) % 10))\n",
    "            features.append(float(hash(\" \".join(card.get(\"traits\", []))) % 10))\n",
    "            effect_emb = card.get(\"effect_embedding\", [0] * EFFECT_DIM)\n",
    "            features.extend(effect_emb)\n",
    "            node_features.append(features)\n",
    "        \n",
    "        if not node_features:\n",
    "            continue\n",
    "\n",
    "        normalized_features = normalize_features(node_features)\n",
    "        for i, node in enumerate(G.nodes()):\n",
    "            for j, attr in enumerate(full_feature_list):\n",
    "                G.nodes[node][attr] = normalized_features[i][j]\n",
    "        # Do not specify group_edge_attrs so edge attributes are ignored.\n",
    "        pyg_data = from_networkx(G, group_node_attrs=full_feature_list)\n",
    "        pyg_graphs.append(pyg_data)\n",
    "    return pyg_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynergyGNN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim=64, out_dim=None):\n",
    "        super(SynergyGNN, self).__init__()\n",
    "        if out_dim is None:\n",
    "            out_dim = in_dim\n",
    "        self.conv1 = GCNConv(in_dim, hidden_dim)\n",
    "        self.bn1 = BatchNorm(hidden_dim)\n",
    "        self.conv2 = GATConv(hidden_dim, hidden_dim)\n",
    "        self.bn2 = BatchNorm(hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.bn2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_synergy_gnn(deck_graphs, card_data, epochs=50, lr=0.001, batch_size=16):\n",
    "    \"\"\"\n",
    "    Train the GNN on deck graphs (winning decks) to learn latent representations.\n",
    "    \"\"\"\n",
    "    pyg_data = convert_to_pyg(deck_graphs, card_data)\n",
    "    loader = DataLoader(pyg_data, batch_size, shuffle=True)\n",
    "    num_features = pyg_data[0].num_features\n",
    "    model = SynergyGNN(in_dim=num_features, out_dim=num_features)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for data in loader:\n",
    "            optimizer.zero_grad()\n",
    "            x, edge_index = data.x, data.edge_index\n",
    "            pred = model(x.float(), edge_index)\n",
    "            pred = pred.view_as(x)\n",
    "            loss = criterion(pred, x.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {total_loss:.4f}\")\n",
    "    return model, num_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, input_dim, path=\"graphs/synergy_gnn.pth\"):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'input_dim': input_dim\n",
    "    }, path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "def load_model(model_path=\"graphs/synergy_gnn.pth\", hidden_dim=32, out_dim=16):\n",
    "    checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    input_dim = checkpoint['input_dim']\n",
    "    model = SynergyGNN(in_dim=input_dim, hidden_dim=hidden_dim, out_dim=out_dim)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    return model, input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_card_embeddings(model, card_data):\n",
    "    \"\"\"\n",
    "    Build a complete card graph (nodes only) and compute an embedding for every card.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    for card_id in card_data.keys():\n",
    "        G.add_node(card_id)\n",
    "    pyg_data = convert_to_pyg([G], card_data)[0]\n",
    "    x, edge_index = pyg_data.x, pyg_data.edge_index\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(x.float(), edge_index).numpy()\n",
    "    card_ids = list(G.nodes())\n",
    "    emb_dict = {cid: embeddings[i] for i, cid in enumerate(card_ids)}\n",
    "    return emb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pairwise_synergy(emb_dict, synergy_graph, alpha=2.0, beta=1.0):\n",
    "    \"\"\"\n",
    "    For each card pair, compute a synergy score based on:\n",
    "      - α * cosine similarity of GNN embeddings, and\n",
    "      - a bonus (β) if a known synergy exists in synergy_graph.\n",
    "    Increasing alpha prioritizes the effect (learned via the GNN).\n",
    "    \"\"\"\n",
    "    card_ids = list(emb_dict.keys())\n",
    "    emb_matrix = np.array([emb_dict[cid] for cid in card_ids])\n",
    "    cos_sim = cosine_similarity(emb_matrix)\n",
    "    synergy_dict = {}\n",
    "    known_synergy = set()\n",
    "    for u, v, data in synergy_graph.edges(data=True):\n",
    "        known_synergy.add(tuple(sorted([u, v])))\n",
    "    n = len(card_ids)\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            cid_i = card_ids[i]\n",
    "            cid_j = card_ids[j]\n",
    "            base = alpha * cos_sim[i, j]\n",
    "            bonus = beta if tuple(sorted([cid_i, cid_j])) in known_synergy else 0.0\n",
    "            synergy_dict[(cid_i, cid_j)] = base + bonus\n",
    "            synergy_dict[(cid_j, cid_i)] = base + bonus\n",
    "    return synergy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_copies(card):\n",
    "    \"\"\"\n",
    "    Determine the maximum allowed copies for a card.\n",
    "    Key cards (labeled \"Main\") are allowed 4 copies.\n",
    "    Event cards (or spice cards) are allowed only 1 copy.\n",
    "    Expensive cards (cost >= 5) are limited to 2-3 copies.\n",
    "    Other cards are allowed 2-3 copies.\n",
    "    \"\"\"\n",
    "    if card[\"type\"] == \"Leader\":\n",
    "        return 1\n",
    "    if \"Main\" in card.get(\"labels\", []):\n",
    "        return 4\n",
    "    if card[\"type\"] == \"Event\":\n",
    "        return 1\n",
    "    if card.get(\"cost\", 0) >= 5:\n",
    "        return random.choice([2, 3])\n",
    "    return random.choice([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_deck(deck, card_data, synergy_dict, w1=1.0, w2=0.5, w3=0.4, w4=0.6):\n",
    "    \"\"\"\n",
    "    Evaluate a deck (dictionary mapping card_id to count) by combining:\n",
    "      - Individual card quality (cost efficiency, power, consistency)\n",
    "      - Pairwise synergy contributions.\n",
    "    \"\"\"\n",
    "    total_individual = 0\n",
    "    for cid, count in deck.items():\n",
    "        card = card_data[cid]\n",
    "        cost_eff = 1 / (card.get(\"cost\", 0) + 1)\n",
    "        power_score = card.get(\"power\", 0) / 10000\n",
    "        consistency = 1.0 if \"Searcher\" in card.get(\"labels\", []) else 0.5\n",
    "        ind_score = w2 * cost_eff + w3 * power_score + w4 * consistency\n",
    "        total_individual += count * ind_score\n",
    "\n",
    "    total_synergy = 0\n",
    "    card_list = []\n",
    "    for cid, count in deck.items():\n",
    "        card_list.extend([cid] * count)\n",
    "    n = len(card_list)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            cid_i = card_list[i]\n",
    "            cid_j = card_list[j]\n",
    "            total_synergy += synergy_dict.get((cid_i, cid_j), 0)\n",
    "    objective = w1 * total_synergy + total_individual\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_deck_greedy(model, card_data, deck_size=50, leader=None):\n",
    "    \"\"\"\n",
    "    Build an initial legal deck by ranking cards based on a composite score\n",
    "    that includes learned synergy (from embeddings) and intrinsic features.\n",
    "    This version also:\n",
    "      - Penalizes cards with no effect text.\n",
    "      - Does not filter out cards that don't share leader traits.\n",
    "      - Uses a helper function to determine maximum allowed copies for variety.\n",
    "    \"\"\"\n",
    "    banned_cards = {\"ST10-001\", \"OP03-098\", \"OP05-041\", \"ST06-015\", \"OP06-116\", \"OP02-024\", \"OP02-052\"}\n",
    "    emb_dict = compute_card_embeddings(model, card_data)\n",
    "    effect_weight = 3.0  # Increase effect importance in the scoring\n",
    "    \n",
    "    def card_score(cid):\n",
    "        card = card_data[cid]\n",
    "        cost_eff = 1 / (card.get(\"cost\", 0) + 1)\n",
    "        power_score = card.get(\"power\", 0) / 10000\n",
    "        consistency = 1.0 if \"Searcher\" in card.get(\"labels\", []) else 0.5\n",
    "        synergy_score = effect_weight * emb_dict[cid].sum()\n",
    "        # Penalize cards with no effect text.\n",
    "        effect_penalty = -10.0 if not card.get(\"effect\", \"\").strip() else 0.0\n",
    "        return synergy_score + cost_eff + power_score + consistency + effect_penalty\n",
    "\n",
    "    ranked_cards = sorted(card_data.keys(), key=card_score, reverse=True)\n",
    "    \n",
    "    # Choose a legal leader.\n",
    "    if leader is None:\n",
    "        for cid in ranked_cards:\n",
    "            if card_data[cid][\"type\"] == \"Leader\" and cid not in banned_cards:\n",
    "                leader = cid\n",
    "                break\n",
    "\n",
    "    else:\n",
    "        if leader not in card_data or card_data[leader][\"type\"] != \"Leader\":\n",
    "            raise ValueError(\"Invalid Leader specified.\")\n",
    "    if leader is None:\n",
    "        raise ValueError(\"No valid Leader found.\")\n",
    "    \n",
    "    leader_color = set(card_data[leader][\"color\"])\n",
    "    \n",
    "    deck = {}\n",
    "    total_cards = 0\n",
    "    for cid in ranked_cards:\n",
    "        if total_cards >= deck_size:\n",
    "            break\n",
    "        if cid == leader or cid in banned_cards or card_data[cid][\"type\"] == \"Leader\":\n",
    "            continue\n",
    "        # Enforce color consistency (if desired).\n",
    "        if not leader_color.intersection(set(card_data[cid][\"color\"])):\n",
    "            continue\n",
    "        max_copies = determine_copies(card_data[cid])\n",
    "        copies = min(max_copies, deck_size - total_cards)\n",
    "        deck[cid] = copies\n",
    "        total_cards += copies\n",
    "\n",
    "    if total_cards != deck_size:\n",
    "        raise ValueError(f\"Greedy deck underfilled: only {total_cards} cards selected.\")\n",
    "    return leader, deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_deck(leader, deck, card_data, synergy_dict, deck_size=50,\n",
    "                  iterations=2000, initial_temp=1.0, cooling_rate=0.995):\n",
    "    \"\"\"\n",
    "    Refine the deck by swapping cards via simulated annealing,\n",
    "    maximizing the overall objective.\n",
    "    \"\"\"\n",
    "    current_deck = deck.copy()\n",
    "    best_deck = deck.copy()\n",
    "    current_obj = evaluate_deck(current_deck, card_data, synergy_dict)\n",
    "    best_obj = current_obj\n",
    "    temp = initial_temp\n",
    "\n",
    "    leader_color = set(card_data[leader][\"color\"])\n",
    "    leader_traits = set(card_data[leader].get(\"traits\", []))\n",
    "    eligible = [cid for cid in card_data if cid != leader and\n",
    "                cid not in {\"ST10-001\", \"OP03-098\", \"OP05-041\", \"ST06-015\", \"OP06-116\", \"OP02-024\", \"OP02-052\"} and\n",
    "                card_data[cid][\"type\"] != \"Leader\" and\n",
    "                leader_color.intersection(set(card_data[cid][\"color\"])) and\n",
    "                leader_traits.intersection(set(card_data[cid].get(\"traits\", [])))]\n",
    "    \n",
    "    current_count = sum(current_deck.values())\n",
    "    if current_count != deck_size:\n",
    "        raise ValueError(\"Initial deck size constraint violated.\")\n",
    "    \n",
    "    for it in range(iterations):\n",
    "        remove_candidate = random.choice(list(current_deck.keys()))\n",
    "        if current_deck[remove_candidate] <= 0:\n",
    "            continue\n",
    "        candidate = random.choice(eligible)\n",
    "        new_deck = current_deck.copy()\n",
    "        new_deck[remove_candidate] -= 1\n",
    "        if new_deck[remove_candidate] == 0:\n",
    "            del new_deck[remove_candidate]\n",
    "        # Respect maximum copies for the candidate.\n",
    "        max_copies_candidate = determine_copies(card_data[candidate])\n",
    "        if new_deck.get(candidate, 0) + 1 > max_copies_candidate:\n",
    "            continue\n",
    "        new_deck[candidate] = new_deck.get(candidate, 0) + 1\n",
    "        new_obj = evaluate_deck(new_deck, card_data, synergy_dict)\n",
    "        delta = new_obj - current_obj\n",
    "        if delta > 0 or random.random() < math.exp(delta / temp):\n",
    "            current_deck = new_deck\n",
    "            current_obj = new_obj\n",
    "            if current_obj > best_obj:\n",
    "                best_deck = current_deck.copy()\n",
    "                best_obj = current_obj\n",
    "        temp *= cooling_rate\n",
    "    print(f\"Optimization complete. Best objective: {best_obj:.4f}\")\n",
    "    return best_deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1732 deck graphs.\n"
     ]
    }
   ],
   "source": [
    "card_data = load_card_attributes(\"data/labeled_cards.json\")\n",
    "synergy_graph = load_card_synergies(\"graphs/card_synergies.graphml\")\n",
    "\n",
    "# Load deck graphs (sample winning decks) from a folder (GraphML files).\n",
    "deck_folder = \"graphs/deck-lists\"\n",
    "deck_graphs = []\n",
    "for file in os.listdir(deck_folder):\n",
    "    if file.endswith(\".graphml\"):\n",
    "        G = nx.read_graphml(os.path.join(deck_folder, file))\n",
    "        deck_graphs.append(G)\n",
    "\n",
    "print(f\"Loaded {len(deck_graphs)} deck graphs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GNN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sandr\\Documents\\Personal-Files\\05-Projects\\gnn-optcg\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 11.4976\n",
      "Epoch 10, Loss: 2.0486\n",
      "Epoch 20, Loss: 1.8138\n",
      "Epoch 30, Loss: 1.7139\n",
      "Epoch 40, Loss: 1.6251\n",
      "Epoch 50, Loss: 1.5264\n",
      "Epoch 60, Loss: 1.4451\n",
      "Epoch 70, Loss: 1.3888\n",
      "Epoch 80, Loss: 1.3445\n",
      "Epoch 90, Loss: 1.3127\n",
      "Epoch 100, Loss: 1.2802\n",
      "Epoch 110, Loss: 1.2660\n",
      "Epoch 120, Loss: 1.2378\n",
      "Epoch 130, Loss: 1.2175\n",
      "Epoch 140, Loss: 1.1947\n",
      "Epoch 150, Loss: 1.1892\n",
      "Epoch 160, Loss: 1.1757\n",
      "Epoch 170, Loss: 1.1625\n",
      "Epoch 180, Loss: 1.1517\n",
      "Epoch 190, Loss: 1.1441\n"
     ]
    }
   ],
   "source": [
    "print(\"Training GNN...\")\n",
    "model, input_dim = train_synergy_gnn(deck_graphs, card_data, epochs=200, batch_size=80, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to graphs/synergy_gnn.pth\n"
     ]
    }
   ],
   "source": [
    "save_model(model, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing card embeddings...\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing card embeddings...\")\n",
    "emb_dict = compute_card_embeddings(model, card_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pairwise synergy scores...\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing pairwise synergy scores...\")\n",
    "synergy_dict = compute_pairwise_synergy(emb_dict, synergy_graph, alpha=2.0, beta=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating initial deck...\n",
      "Initial deck objective: 1959.9707\n",
      "Initial Deck List:\n",
      "1xOP04-040\n",
      "2xOP05-047\n",
      "2xOP04-053\n",
      "2xOP04-100\n",
      "2xOP02-063\n",
      "2xST12-010\n",
      "2xST13-006\n",
      "3xEB01-024\n",
      "3xOP07-107\n",
      "2xOP02-059\n",
      "2xOP06-114\n",
      "3xOP07-054\n",
      "3xOP01-068\n",
      "3xOP01-078\n",
      "2xOP06-052\n",
      "3xST09-003\n",
      "3xOP05-118\n",
      "3xOP03-106\n",
      "4xOP08-103\n",
      "3xST07-012\n",
      "1xOP04-101\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating initial deck...\")\n",
    "leader, init_deck = generate_deck_greedy(model, card_data, deck_size=50)\n",
    "init_obj = evaluate_deck(init_deck, card_data, synergy_dict)\n",
    "print(f\"Initial deck objective: {init_obj:.4f}\")\n",
    "\n",
    "initial_deck_list = [f\"1x{leader}\"]\n",
    "for card, count in init_deck.items():\n",
    "    initial_deck_list.append(f\"{count}x{card}\")\n",
    "\n",
    "print(\"Initial Deck List:\")\n",
    "print(\"\\n\".join(initial_deck_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing deck using simulated annealing...\n",
      "Optimization complete. Best objective: 2541.5220\n",
      "Optimized Deck List:\n",
      "1xOP04-040\n",
      "2xST12-010\n",
      "3xOP07-107\n",
      "2xOP07-054\n",
      "2xOP06-052\n",
      "3xST09-003\n",
      "3xOP05-118\n",
      "2xST07-012\n",
      "1xOP04-101\n",
      "4xOP04-055\n",
      "4xOP04-052\n",
      "3xST09-004\n",
      "3xOP04-047\n",
      "3xOP04-045\n",
      "3xOP04-048\n",
      "3xOP04-049\n",
      "3xOP05-049\n",
      "3xEB01-024\n",
      "3xOP05-043\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimizing deck using simulated annealing...\")\n",
    "optimized_deck = optimize_deck(leader, init_deck, card_data, synergy_dict,\n",
    "                                   deck_size=50, iterations=2000)\n",
    "\n",
    "deck_list = [f\"1x{leader}\"]\n",
    "for cid, count in optimized_deck.items():\n",
    "    deck_list.append(f\"{count}x{cid}\")\n",
    "\n",
    "print(\"Optimized Deck List:\")\n",
    "print(\"\\n\".join(deck_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move evaluation and storing of the decklist to functions, then add deck optimization.\n",
    "\n",
    "def build_and_save_synergy_graph(deck, synergy_dict, output_path):\n",
    "    G = nx.Graph()\n",
    "    cards = [cid for cid, count in deck.items() for _ in range(count)]\n",
    "    for cid in cards:\n",
    "        if not G.has_node(cid):\n",
    "            G.add_node(cid)\n",
    "    for i, cid_a in enumerate(cards):\n",
    "        for j, cid_b in enumerate(cards):\n",
    "            if j > i:\n",
    "                syn_score = synergy_dict.get((cid_a, cid_b), 0)\n",
    "                G.add_edge(cid_a, cid_b, synergy=syn_score)\n",
    "    nx.write_graphml(G, output_path)\n",
    "\n",
    "def save_deck_list(leader_cid, deck, output_path):\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.write(f\"1x{leader_cid}\\n\")\n",
    "        for cid, count in deck.items():\n",
    "            f.write(f\"{count}x{cid}\\n\")\n",
    "\n",
    "    print(f\"Deck list saved to {output_path}\")\n",
    "\n",
    "def process_deck(leader_cid, index, model, card_data, synergy_dict, stats_file,\n",
    "                 deck_graph_dir, deck_list_dir, deck_size=50):\n",
    "    # Generate and evaluate initial deck\n",
    "    ldr_str, deck = generate_deck_greedy(model, card_data, deck_size=deck_size, leader=leader_cid)\n",
    "    score_init = evaluate_deck(deck, card_data, synergy_dict)\n",
    "\n",
    "    # Optimize and evaluate optimized deck\n",
    "    deck_opt = optimize_deck(leader_cid, deck, card_data, synergy_dict, deck_size=deck_size)\n",
    "    score_opt = evaluate_deck(deck_opt, card_data, synergy_dict)\n",
    "\n",
    "    # Store results\n",
    "    with open(stats_file, \"a\") as f:\n",
    "        f.write(f\"{leader_cid},{index},{score_init:.4f},{score_opt:.4f}\\n\")\n",
    "\n",
    "    # Save synergy graphs and deck lists\n",
    "    graph_path_init = os.path.join(deck_graph_dir, \"initial\", f\"deck_{index}.graphml\")\n",
    "    list_path_init = os.path.join(deck_list_dir, \"initial\", f\"deck_{index}.txt\")\n",
    "    build_and_save_synergy_graph(deck, synergy_dict, graph_path_init)\n",
    "    save_deck_list(ldr_str, deck, list_path_init)\n",
    "\n",
    "    graph_path_opt = os.path.join(deck_graph_dir, \"optimized\", f\"deck_{index}.graphml\")\n",
    "    list_path_opt = os.path.join(deck_list_dir, \"optimized\", f\"deck_{index}.txt\")\n",
    "    build_and_save_synergy_graph(deck_opt, synergy_dict, graph_path_opt)\n",
    "    save_deck_list(ldr_str, deck_opt, list_path_opt)\n",
    "\n",
    "    print(f\"[Leader {leader_cid}] Deck {index} generated (score={score_init:.4f}), optimized (score={score_opt:.4f}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization complete. Best objective: 3155.0032\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_1.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_1.txt\n",
      "[Leader OP01-003] Deck 1 generated (score=1372.0535), optimized (score=3155.0032).\n",
      "Optimization complete. Best objective: 3137.8003\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_2.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_2.txt\n",
      "[Leader OP01-003] Deck 2 generated (score=1223.6913), optimized (score=3137.8003).\n",
      "Optimization complete. Best objective: 3181.3621\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_3.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_3.txt\n",
      "[Leader OP01-003] Deck 3 generated (score=1521.7756), optimized (score=3181.3621).\n",
      "Optimization complete. Best objective: 3127.7297\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_4.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_4.txt\n",
      "[Leader OP01-003] Deck 4 generated (score=1515.4814), optimized (score=3127.7297).\n",
      "Optimization complete. Best objective: 3153.3081\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_5.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_5.txt\n",
      "[Leader OP01-003] Deck 5 generated (score=1566.7179), optimized (score=3153.3081).\n",
      "Optimization complete. Best objective: 3141.2480\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_6.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_6.txt\n",
      "[Leader OP01-003] Deck 6 generated (score=1360.8418), optimized (score=3141.2480).\n",
      "Optimization complete. Best objective: 3150.7019\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_7.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_7.txt\n",
      "[Leader OP01-003] Deck 7 generated (score=1295.8051), optimized (score=3150.7019).\n",
      "Optimization complete. Best objective: 3137.7910\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_8.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_8.txt\n",
      "[Leader OP01-003] Deck 8 generated (score=1421.6688), optimized (score=3137.7910).\n",
      "Optimization complete. Best objective: 3148.0266\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_9.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_9.txt\n",
      "[Leader OP01-003] Deck 9 generated (score=1154.1188), optimized (score=3148.0266).\n",
      "Optimization complete. Best objective: 3234.9658\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_10.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_10.txt\n",
      "[Leader OP01-003] Deck 10 generated (score=1652.8029), optimized (score=3234.9658).\n",
      "Optimization complete. Best objective: 3139.1396\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_11.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_11.txt\n",
      "[Leader OP01-003] Deck 11 generated (score=1653.4290), optimized (score=3139.1396).\n",
      "Optimization complete. Best objective: 3119.8401\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_12.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_12.txt\n",
      "[Leader OP01-003] Deck 12 generated (score=1261.3864), optimized (score=3119.8401).\n",
      "Optimization complete. Best objective: 3147.1865\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_13.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_13.txt\n",
      "[Leader OP01-003] Deck 13 generated (score=1624.4590), optimized (score=3147.1865).\n",
      "Optimization complete. Best objective: 3151.2991\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_14.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_14.txt\n",
      "[Leader OP01-003] Deck 14 generated (score=1406.1727), optimized (score=3151.2991).\n",
      "Optimization complete. Best objective: 3165.8577\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_15.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_15.txt\n",
      "[Leader OP01-003] Deck 15 generated (score=1421.5177), optimized (score=3165.8577).\n",
      "Optimization complete. Best objective: 3122.6455\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_16.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_16.txt\n",
      "[Leader OP01-003] Deck 16 generated (score=1326.1084), optimized (score=3122.6455).\n",
      "Optimization complete. Best objective: 3163.3994\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_17.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_17.txt\n",
      "[Leader OP01-003] Deck 17 generated (score=1485.5001), optimized (score=3163.3994).\n",
      "Optimization complete. Best objective: 3125.5779\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_18.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_18.txt\n",
      "[Leader OP01-003] Deck 18 generated (score=1686.9183), optimized (score=3125.5779).\n",
      "Optimization complete. Best objective: 3140.1121\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_19.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_19.txt\n",
      "[Leader OP01-003] Deck 19 generated (score=1255.4435), optimized (score=3140.1121).\n",
      "Optimization complete. Best objective: 3154.3196\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_20.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_20.txt\n",
      "[Leader OP01-003] Deck 20 generated (score=1511.9023), optimized (score=3154.3196).\n",
      "Optimization complete. Best objective: 3120.6946\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_21.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_21.txt\n",
      "[Leader OP01-003] Deck 21 generated (score=1205.0863), optimized (score=3120.6946).\n",
      "Optimization complete. Best objective: 3135.3225\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_22.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_22.txt\n",
      "[Leader OP01-003] Deck 22 generated (score=1377.2313), optimized (score=3135.3225).\n",
      "Optimization complete. Best objective: 3168.1868\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\initial\\deck_23.txt\n",
      "Deck list saved to evaluation\\decks\\OP01-003\\lists\\optimized\\deck_23.txt\n",
      "[Leader OP01-003] Deck 23 generated (score=1561.6431), optimized (score=3168.1868).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 23\u001b[0m         process_deck(\n\u001b[0;32m     24\u001b[0m             leader_cid, i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, model, card_data, synergy_dict, stats_file,\n\u001b[0;32m     25\u001b[0m             deck_graph_dir, deck_list_dir, deck_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\n\u001b[0;32m     26\u001b[0m         )\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Leader \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mleader_cid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Deck \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[42], line 27\u001b[0m, in \u001b[0;36mprocess_deck\u001b[1;34m(leader_cid, index, model, card_data, synergy_dict, stats_file, deck_graph_dir, deck_list_dir, deck_size)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_deck\u001b[39m(leader_cid, index, model, card_data, synergy_dict, stats_file,\n\u001b[0;32m     25\u001b[0m                  deck_graph_dir, deck_list_dir, deck_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# Generate and evaluate initial deck\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     ldr_str, deck \u001b[38;5;241m=\u001b[39m generate_deck_greedy(model, card_data, deck_size\u001b[38;5;241m=\u001b[39mdeck_size, leader\u001b[38;5;241m=\u001b[39mleader_cid)\n\u001b[0;32m     28\u001b[0m     score_init \u001b[38;5;241m=\u001b[39m evaluate_deck(deck, card_data, synergy_dict)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Optimize and evaluate optimized deck\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[44], line 11\u001b[0m, in \u001b[0;36mgenerate_deck_greedy\u001b[1;34m(model, card_data, deck_size, leader)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mBuild an initial legal deck by ranking cards based on a composite score\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mthat includes learned synergy (from embeddings) and intrinsic features.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m  - Uses a helper function to determine maximum allowed copies for variety.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m banned_cards \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mST10-001\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOP03-098\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOP05-041\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mST06-015\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOP06-116\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOP02-024\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOP02-052\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m---> 11\u001b[0m emb_dict \u001b[38;5;241m=\u001b[39m compute_card_embeddings(model, card_data)\n\u001b[0;32m     12\u001b[0m effect_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3.0\u001b[39m  \u001b[38;5;66;03m# Increase effect importance in the scoring\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcard_score\u001b[39m(cid):\n",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m, in \u001b[0;36mcompute_card_embeddings\u001b[1;34m(model, card_data)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m card_id \u001b[38;5;129;01min\u001b[39;00m card_data\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m      7\u001b[0m     G\u001b[38;5;241m.\u001b[39madd_node(card_id)\n\u001b[1;32m----> 8\u001b[0m pyg_data \u001b[38;5;241m=\u001b[39m convert_to_pyg([G], card_data)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      9\u001b[0m x, edge_index \u001b[38;5;241m=\u001b[39m pyg_data\u001b[38;5;241m.\u001b[39mx, pyg_data\u001b[38;5;241m.\u001b[39medge_index\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "Cell \u001b[1;32mIn[6], line 54\u001b[0m, in \u001b[0;36mconvert_to_pyg\u001b[1;34m(graphs, card_data)\u001b[0m\n\u001b[0;32m     52\u001b[0m             G\u001b[38;5;241m.\u001b[39mnodes[node][attr] \u001b[38;5;241m=\u001b[39m normalized_features[i][j]\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# Do not specify group_edge_attrs so edge attributes are ignored.\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     pyg_data \u001b[38;5;241m=\u001b[39m from_networkx(G, group_node_attrs\u001b[38;5;241m=\u001b[39mfull_feature_list)\n\u001b[0;32m     55\u001b[0m     pyg_graphs\u001b[38;5;241m.\u001b[39mappend(pyg_data)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pyg_graphs\n",
      "File \u001b[1;32mc:\\Users\\sandr\\Documents\\Personal-Files\\05-Projects\\gnn-optcg\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\torch_geometric\\utils\\convert.py:229\u001b[0m, in \u001b[0;36mfrom_networkx\u001b[1;34m(G, group_node_attrs, group_edge_attrs)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[1;32m--> 229\u001b[0m G \u001b[38;5;241m=\u001b[39m G\u001b[38;5;241m.\u001b[39mto_directed() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nx\u001b[38;5;241m.\u001b[39mis_directed(G) \u001b[38;5;28;01melse\u001b[39;00m G\n\u001b[0;32m    231\u001b[0m mapping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(G\u001b[38;5;241m.\u001b[39mnodes(), \u001b[38;5;28mrange\u001b[39m(G\u001b[38;5;241m.\u001b[39mnumber_of_nodes())))\n\u001b[0;32m    232\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;241m2\u001b[39m, G\u001b[38;5;241m.\u001b[39mnumber_of_edges()), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
      "File \u001b[1;32mc:\\Users\\sandr\\Documents\\Personal-Files\\05-Projects\\gnn-optcg\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\networkx\\classes\\graph.py:1703\u001b[0m, in \u001b[0;36mGraph.to_directed\u001b[1;34m(self, as_view)\u001b[0m\n\u001b[0;32m   1701\u001b[0m G \u001b[38;5;241m=\u001b[39m graph_class()\n\u001b[0;32m   1702\u001b[0m G\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mupdate(deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph))\n\u001b[1;32m-> 1703\u001b[0m G\u001b[38;5;241m.\u001b[39madd_nodes_from((n, deepcopy(d)) \u001b[38;5;28;01mfor\u001b[39;00m n, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m   1704\u001b[0m G\u001b[38;5;241m.\u001b[39madd_edges_from(\n\u001b[0;32m   1705\u001b[0m     (u, v, deepcopy(data))\n\u001b[0;32m   1706\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m u, nbrs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adj\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1707\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m v, data \u001b[38;5;129;01min\u001b[39;00m nbrs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1708\u001b[0m )\n\u001b[0;32m   1709\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m G\n",
      "File \u001b[1;32mc:\\Users\\sandr\\Documents\\Personal-Files\\05-Projects\\gnn-optcg\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\networkx\\classes\\digraph.py:532\u001b[0m, in \u001b[0;36mDiGraph.add_nodes_from\u001b[1;34m(self, nodes_for_adding, **attr)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_nodes_from\u001b[39m(\u001b[38;5;28mself\u001b[39m, nodes_for_adding, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mattr):\n\u001b[0;32m    472\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Add multiple nodes.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;124;03m    >>> G.add_nodes_from(list(n + 1 for n in G.nodes))\u001b[39;00m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 532\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m nodes_for_adding:\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    534\u001b[0m             newnode \u001b[38;5;241m=\u001b[39m n \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node\n",
      "File \u001b[1;32mc:\\Users\\sandr\\Documents\\Personal-Files\\05-Projects\\gnn-optcg\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\networkx\\classes\\graph.py:1703\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1701\u001b[0m G \u001b[38;5;241m=\u001b[39m graph_class()\n\u001b[0;32m   1702\u001b[0m G\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mupdate(deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph))\n\u001b[1;32m-> 1703\u001b[0m G\u001b[38;5;241m.\u001b[39madd_nodes_from((n, deepcopy(d)) \u001b[38;5;28;01mfor\u001b[39;00m n, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m   1704\u001b[0m G\u001b[38;5;241m.\u001b[39madd_edges_from(\n\u001b[0;32m   1705\u001b[0m     (u, v, deepcopy(data))\n\u001b[0;32m   1706\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m u, nbrs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adj\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1707\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m v, data \u001b[38;5;129;01min\u001b[39;00m nbrs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1708\u001b[0m )\n\u001b[0;32m   1709\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m G\n",
      "File \u001b[1;32mc:\\Users\\sandr\\Documents\\Personal-Files\\05-Projects\\gnn-optcg\\code\\optcg-gnn\\.conda\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\sandr\\Documents\\Personal-Files\\05-Projects\\gnn-optcg\\code\\optcg-gnn\\.conda\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\sandr\\Documents\\Personal-Files\\05-Projects\\gnn-optcg\\code\\optcg-gnn\\.conda\\Lib\\copy.py:177\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n\u001b[0;32m    176\u001b[0m     memo[d] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m--> 177\u001b[0m     _keep_alive(x, memo) \u001b[38;5;66;03m# Make sure x lives at least as long as d\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\sandr\\Documents\\Personal-Files\\05-Projects\\gnn-optcg\\code\\optcg-gnn\\.conda\\Lib\\copy.py:254\u001b[0m, in \u001b[0;36m_keep_alive\u001b[1;34m(x, memo)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Keeps a reference to the object x in the memo.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03mBecause we remember objects by their id, we have\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03mthe memo itself...\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 254\u001b[0m     memo[\u001b[38;5;28mid\u001b[39m(memo)]\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;66;03m# aha, this is the first one :-)\u001b[39;00m\n\u001b[0;32m    257\u001b[0m     memo[\u001b[38;5;28mid\u001b[39m(memo)]\u001b[38;5;241m=\u001b[39m[x]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main code to iterate over leaders and decks (with updated stats file header).\n",
    "output_dir = \"evaluation\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "stats_file = os.path.join(output_dir, \"stats.csv\")\n",
    "possible_leaders = [cid for cid in card_data if card_data[cid][\"type\"] == \"Leader\"]\n",
    "\n",
    "with open(stats_file, \"w\") as f:\n",
    "    f.write(\"leader,deck_index,score_init,score_opt\\n\")\n",
    "\n",
    "for leader_cid in possible_leaders:\n",
    "    deck_graph_dir = os.path.join(output_dir, \"decks\", leader_cid, \"graphs\")\n",
    "    deck_list_dir = os.path.join(output_dir, \"decks\", leader_cid, \"lists\")\n",
    "\n",
    "    os.makedirs(deck_graph_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.join(deck_graph_dir, \"initial\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(deck_graph_dir, \"optimized\"), exist_ok=True)\n",
    "    os.makedirs(deck_list_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.join(deck_list_dir, \"initial\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(deck_list_dir, \"optimized\"), exist_ok=True)\n",
    "\n",
    "    for i in range(1000):\n",
    "        try:\n",
    "            process_deck(\n",
    "                leader_cid, i+1, model, card_data, synergy_dict, stats_file,\n",
    "                deck_graph_dir, deck_list_dir, deck_size=50\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[Leader {leader_cid}] Deck {i+1} failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
