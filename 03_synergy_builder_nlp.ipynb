{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/labeled_cards.json') as f:\n",
    "    cards = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E007] 'custom_ner_component' already exists in pipeline. Existing names: ['tok2vec', 'tagger', 'parser', 'senter', 'attribute_ruler', 'lemmatizer', 'ner', 'custom_ner_component']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 102\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m doc\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Add custom NER component to the pipeline\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m nlp\u001b[38;5;241m.\u001b[39madd_pipe(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_ner_component\u001b[39m\u001b[38;5;124m\"\u001b[39m, after\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_synergies\u001b[39m(cards):\n\u001b[0;32m    105\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    Finds synergies between cards based on parsed effects.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\spacy\\language.py:810\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    808\u001b[0m name \u001b[38;5;241m=\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m factory_name\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_names:\n\u001b[1;32m--> 810\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE007\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, opts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_names))\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# Overriding pipe name in the config is not supported and will be ignored.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "\u001b[1;31mValueError\u001b[0m: [E007] 'custom_ner_component' already exists in pipeline. Existing names: ['tok2vec', 'tagger', 'parser', 'senter', 'attribute_ruler', 'lemmatizer', 'ner', 'custom_ner_component']"
     ]
    }
   ],
   "source": [
    "def parse_card_effect(effect_text):\n",
    "    \"\"\"\n",
    "    Parses the card effect text using NLP to extract structured information.\n",
    "    \"\"\"\n",
    "    doc = nlp(effect_text)\n",
    "\n",
    "    parsed_effect = {\n",
    "        'actions': [],\n",
    "        'conditions': [],\n",
    "        'targets': []\n",
    "    }\n",
    "\n",
    "    # Initialize Matcher\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "    # Define patterns for actions\n",
    "    action_patterns = [\n",
    "        [{'LEMMA': 'reveal'}],\n",
    "        [{'LEMMA': 'play'}],\n",
    "        [{'LEMMA': 'add'}],\n",
    "        [{'LEMMA': 'draw'}],\n",
    "        [{'LEMMA': 'return'}],\n",
    "        [{'LEMMA': 'KO'}],\n",
    "        [{'LEMMA': 'give'}],\n",
    "        [{'LEMMA': 'look'}],\n",
    "        [{'LEMMA': 'trash'}],\n",
    "        [{'LEMMA': 'rest'}],\n",
    "        [{'LEMMA': 'gain'}],\n",
    "        [{'LEMMA': 'set'}],\n",
    "        [{'LEMMA': 'activate'}],\n",
    "    ]\n",
    "    matcher.add('ACTIONS', action_patterns)\n",
    "\n",
    "    # Define patterns for conditions\n",
    "    condition_patterns = [\n",
    "        [{'LOWER': 'if'}, {'OP': '*'}, {'LOWER': 'you'}, {'OP': '*'}, {'LOWER': 'control'}],\n",
    "        [{'LOWER': 'if'}, {'OP': '*'}, {'LOWER': 'your'}, {'OP': '*'}, {'LOWER': 'leader'}],\n",
    "        [{'LOWER': 'during'}, {'LOWER': 'your'}, {'LOWER': 'turn'}],\n",
    "        [{'LOWER': 'once'}, {'LOWER': 'per'}, {'LOWER': 'turn'}],\n",
    "    ]\n",
    "    matcher.add('CONDITIONS', condition_patterns)\n",
    "\n",
    "    # Define patterns for targets\n",
    "    target_patterns = [\n",
    "        [{'LOWER': 'character'}, {'LOWER': 'card'}, {'LOWER': 'with'}, {'LOWER': 'a'}, {'LOWER': 'cost'}, {'IS_DIGIT': True}],\n",
    "        [{'LOWER': 'character'}, {'LOWER': 'card'}, {'LOWER': 'with'}, {'LOWER': 'cost'}, {'IS_DIGIT': True}, {'LOWER': 'or'}, {'LOWER': 'less'}],\n",
    "        [{'LOWER': 'character'}, {'LOWER': 'card'}, {'LOWER': 'with'}, {'LOWER': 'cost'}, {'IS_DIGIT': True}, {'LOWER': 'to'}, {'IS_DIGIT': True}],\n",
    "        [{'LOWER': 'character'}, {'LOWER': 'card'}, {'LOWER': 'with'}, {'LOWER': 'trait'}, {'LOWER': '{'}, {'ENT_TYPE': 'TRAIT'}, {'LOWER': '}'}],\n",
    "        [{'LOWER': 'your'}, {'LOWER': 'opponents'}, {'LOWER': 'character'}, {'LOWER': 'with'}, {'LOWER': 'cost'}, {'IS_DIGIT': True}, {'LOWER': 'or'}, {'LOWER': 'less'}],\n",
    "    ]\n",
    "    matcher.add('TARGETS', target_patterns)\n",
    "\n",
    "    # Apply the matcher to the doc\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    # Process matches\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        label = nlp.vocab.strings[match_id]\n",
    "\n",
    "        if label == 'ACTIONS':\n",
    "            action = span.lemma_\n",
    "            parsed_effect['actions'].append(action)\n",
    "        elif label == 'CONDITIONS':\n",
    "            condition = span.text\n",
    "            parsed_effect['conditions'].append(condition)\n",
    "        elif label == 'TARGETS':\n",
    "            target = span.text\n",
    "            parsed_effect['targets'].append(target)\n",
    "\n",
    "    # Extract traits and exclusions\n",
    "    trait_entities = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'TRAIT':\n",
    "            trait_entities.append(ent.text)\n",
    "\n",
    "    parsed_effect['traits'] = trait_entities\n",
    "\n",
    "    # Additional parsing logic can be added here\n",
    "\n",
    "    return parsed_effect\n",
    "\n",
    "from spacy.language import Language\n",
    "\n",
    "# Custom NER component to recognize game-specific entities\n",
    "@Language.component(\"custom_ner_component\")\n",
    "def custom_ner_component(doc):\n",
    "    # Add custom entity recognition for traits and other game terms\n",
    "    for ent in doc.ents:\n",
    "        continue  # Keep existing entities\n",
    "\n",
    "    # Manually add entities\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.text.startswith('{') and token.text.endswith('}'):\n",
    "            trait = token.text.strip('{}')\n",
    "            span = doc[i:i+1]\n",
    "            doc.ents += ((span.start_char, span.end_char, 'TRAIT'),)\n",
    "\n",
    "    return doc\n",
    "\n",
    "# Add custom NER component to the pipeline\n",
    "nlp.add_pipe(\"custom_ner_component\", after='ner')\n",
    "\n",
    "def find_synergies(cards):\n",
    "    \"\"\"\n",
    "    Finds synergies between cards based on parsed effects.\n",
    "    \"\"\"\n",
    "    # Parse effects of all cards\n",
    "    parsed_cards = {}\n",
    "    for card in cards:\n",
    "        effect = card.get('effect', '')\n",
    "        parsed_effect = parse_card_effect(effect)\n",
    "        card['parsed_effect'] = parsed_effect\n",
    "        parsed_cards[card['id']] = card\n",
    "\n",
    "    synergies = defaultdict(list)\n",
    "\n",
    "    for card in cards:\n",
    "        card_id = card['id']\n",
    "        card_name = card['name']\n",
    "        card_parsed = card['parsed_effect']\n",
    "\n",
    "        # Initialize synergy list for this card\n",
    "        synergies[card_id] = {'name': card_name, 'synergies': []}\n",
    "\n",
    "        # Identify synergies based on actions\n",
    "        for action in card_parsed['actions']:\n",
    "            if action == 'reveal':\n",
    "                # Find trait being searched\n",
    "                search_traits = card_parsed.get('traits', [])\n",
    "                exclude_name = card.get('name', '').lower()\n",
    "                for target_card in cards:\n",
    "                    if (any(trait in target_card.get('traits', []) for trait in search_traits) and\n",
    "                            target_card['id'] != card_id and\n",
    "                            target_card['name'].lower() != exclude_name):\n",
    "                        synergy_info = {\n",
    "                            'id': target_card['id'],\n",
    "                            'name': target_card['name'],\n",
    "                            'traits': target_card.get('traits', []),\n",
    "                            'cost': target_card['cost'],\n",
    "                            'synergy_score': 1\n",
    "                        }\n",
    "                        synergies[card_id]['synergies'].append(synergy_info)\n",
    "            elif action == 'play':\n",
    "                # Find cards that can be played based on conditions\n",
    "                targets = card_parsed.get('targets', [])\n",
    "                for target in targets:\n",
    "                    # Parse target conditions\n",
    "                    cost_match = re.search(r'cost (\\d+)', target)\n",
    "                    cost = int(cost_match.group(1)) if cost_match else None\n",
    "                    if cost:\n",
    "                        for target_card in cards:\n",
    "                            if (target_card['type'] == 'Character' and\n",
    "                                    target_card['cost'] <= cost and\n",
    "                                    target_card['id'] != card_id):\n",
    "                                synergy_score = 0\n",
    "                                if 'on play' in target_card.get('effect', '').lower():\n",
    "                                    synergy_score += 1\n",
    "                                if set(card.get('traits', [])) & set(target_card.get('traits', [])):\n",
    "                                    synergy_score += 1\n",
    "                                synergy_info = {\n",
    "                                    'id': target_card['id'],\n",
    "                                    'name': target_card['name'],\n",
    "                                    'cost': target_card['cost'],\n",
    "                                    'synergy_score': synergy_score\n",
    "                                }\n",
    "                                synergies[card_id]['synergies'].append(synergy_info)\n",
    "            elif action == 'add':\n",
    "                # Handle 'add' actions (e.g., adding from trash)\n",
    "                conditions = card_parsed.get('conditions', [])\n",
    "                targets = card_parsed.get('targets', [])\n",
    "                for target in targets:\n",
    "                    # Parse target conditions\n",
    "                    cost_range = re.search(r'cost of (\\d+) to (\\d+)', target)\n",
    "                    if cost_range:\n",
    "                        cost_min = int(cost_range.group(1))\n",
    "                        cost_max = int(cost_range.group(2))\n",
    "                        for target_card in cards:\n",
    "                            if (cost_min <= target_card['cost'] <= cost_max and\n",
    "                                    target_card['id'] != card_id):\n",
    "                                synergy_info = {\n",
    "                                    'id': target_card['id'],\n",
    "                                    'name': target_card['name'],\n",
    "                                    'cost': target_card['cost'],\n",
    "                                    'synergy_score': 1\n",
    "                                }\n",
    "                                synergies[card_id]['synergies'].append(synergy_info)\n",
    "\n",
    "        # Remove duplicates and sort synergies\n",
    "        unique_synergies = {s['id']: s for s in synergies[card_id]['synergies']}.values()\n",
    "        synergies[card_id]['synergies'] = sorted(unique_synergies, key=lambda x: x['synergy_score'], reverse=True)\n",
    "\n",
    "    return synergies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the function and print the synergies\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m synergy_results \u001b[38;5;241m=\u001b[39m find_synergies(cards)\n",
      "Cell \u001b[1;32mIn[10], line 112\u001b[0m, in \u001b[0;36mfind_synergies\u001b[1;34m(cards)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m card \u001b[38;5;129;01min\u001b[39;00m cards:\n\u001b[0;32m    111\u001b[0m     effect \u001b[38;5;241m=\u001b[39m card\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meffect\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 112\u001b[0m     parsed_effect \u001b[38;5;241m=\u001b[39m parse_card_effect(effect)\n\u001b[0;32m    113\u001b[0m     card[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparsed_effect\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parsed_effect\n\u001b[0;32m    114\u001b[0m     parsed_cards[card[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m card\n",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m, in \u001b[0;36mparse_card_effect\u001b[1;34m(effect_text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_card_effect\u001b[39m(effect_text):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Parses the card effect text using NLP to extract structured information.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     doc \u001b[38;5;241m=\u001b[39m nlp(effect_text)\n\u001b[0;32m      7\u001b[0m     parsed_effect \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconditions\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m'\u001b[39m: []\n\u001b[0;32m     11\u001b[0m     }\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Initialize Matcher\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\spacy\\language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1049\u001b[0m     doc \u001b[38;5;241m=\u001b[39m proc(doc, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponent_cfg\u001b[38;5;241m.\u001b[39mget(name, {}))  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\spacy\\pipeline\\tok2vec.py:126\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[1;34m(self, docs)\u001b[0m\n\u001b[0;32m    124\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc((\u001b[38;5;241m0\u001b[39m, width)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[1;32m--> 126\u001b[0m tokvecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(docs)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokvecs\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\thinc\\model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[0;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\thinc\\layers\\with_array.py:42\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m](Xseq, is_train)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\thinc\\layers\\with_array.py:77\u001b[0m, in \u001b[0;36m_list_forward\u001b[1;34m(model, Xs, is_train)\u001b[0m\n\u001b[0;32m     75\u001b[0m lengths \u001b[38;5;241m=\u001b[39m NUMPY_OPS\u001b[38;5;241m.\u001b[39masarray1i([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m Xs])\n\u001b[0;32m     76\u001b[0m Xf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(Xs, pad\u001b[38;5;241m=\u001b[39mpad)\n\u001b[1;32m---> 77\u001b[0m Yf, get_dXf \u001b[38;5;241m=\u001b[39m layer(Xf, is_train)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYs: ListXd) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ListXd:\n\u001b[0;32m     80\u001b[0m     dYf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(dYs, pad\u001b[38;5;241m=\u001b[39mpad)\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\thinc\\layers\\residual.py:41\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m d_output \u001b[38;5;241m+\u001b[39m dX\n\u001b[1;32m---> 41\u001b[0m Y, backprop_layer \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m](X, is_train)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [X[i] \u001b[38;5;241m+\u001b[39m Y[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))], backprop\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "    \u001b[1;31m[... skipping similar frames: Model.__call__ at line 310 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32mc:\\Users\\sandr\\OneDrive\\Dokumente\\Schule\\FFHS\\Semester 9\\Thesis\\GNN-TCG\\code\\optcg-gnn\\.conda\\Lib\\site-packages\\thinc\\layers\\maxout.py:52\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     50\u001b[0m W \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m W \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape2f(W, nO \u001b[38;5;241m*\u001b[39m nP, nI)\n\u001b[1;32m---> 52\u001b[0m Y \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mgemm(X, W, trans2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m Y \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape1f(b, nO \u001b[38;5;241m*\u001b[39m nP)\n\u001b[0;32m     54\u001b[0m Z \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape3f(Y, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], nO, nP)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print cards head\n",
    "print(cards[0])\n",
    "\n",
    "# Run the function and print the synergies\n",
    "synergy_results = find_synergies(cards)\n",
    "\n",
    "print (synergy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for card_id, data in synergy_results.items():\n",
    "    name = data['name']\n",
    "    synergies = data['synergies']\n",
    "    if synergies:\n",
    "        print(f\"Synergies for {name} ({card_id}):\")\n",
    "        for s in synergies:\n",
    "            print(f\" - {s['name']} ({s['id']}), Cost: {s['cost']}, Synergy Score: {s.get('synergy_score', 0)}\")\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
